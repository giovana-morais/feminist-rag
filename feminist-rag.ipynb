{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import uuid\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name='all-MiniLM-L6-v2')\n",
    "metadata_options = {\"hnsw:space\": \"cosine\" }\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(name=\"data-feminism\", metadata=metadata_options, embedding_function=sentence_transformer_ef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all chapters to embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# folder_path = 'docs'\n",
    "# for root, _, files in os.walk(folder_path):\n",
    "#     for file in files:\n",
    "#         file_path = os.path.join(root, file)\n",
    "#         print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert just one chapter to embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"docs/Ch1.pdf\")\n",
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(data)\n",
    "for doc in docs:\n",
    "    uuid_name = uuid.uuid1()\n",
    "    collection.add(ids=[str(uuid_name)], documents=doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query_text):\n",
    "    results = collection.query(query_texts=[query_text],n_results=6)\n",
    "    return results['documents']\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "  # Create a list to store all the messages for context\n",
    "  messages = []\n",
    "  messages.append({\"role\": \"system\", \"content\": \"You are a helpful assistant who's been given Data Feminism Chapter as context. When the user asks a question, use the data feminism context to answer the question. If the message is a greeting, just respond normally.\" })  \n",
    "  \n",
    "  while True:\n",
    "    # list to store all the retrievals from Chroma\n",
    "    context = []\n",
    "    \n",
    "    # Prompt user for input\n",
    "    message = input(\"User: \")\n",
    "    print(f\"User: {message}\"+'\\n')\n",
    "    \n",
    "    # Exit program if user inputs \"quit\"\n",
    "    if message.lower() == \"quit\":\n",
    "      break\n",
    "    \n",
    "    #retrieve necessary context\n",
    "    context = retrieve_context(message)\n",
    "    # context_string = ', '.join([str(elem) for elem in context])\n",
    "    \n",
    "    message_with_context = f''' \n",
    "    \n",
    "    You are a helpful bot who answers concisely. Use this context: \n",
    "    {context} \n",
    "    \n",
    "    To answer the question: {message}. \n",
    "    \n",
    "    If you don't know the answer from the context, say you don't know.\n",
    "    '''\n",
    "    \n",
    "    # Add each new message to the list\n",
    "    messages.append({\"role\": \"user\", \"content\": message_with_context})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"llama3\",\n",
    "      messages=[{\"role\": \"user\", \"content\": message_with_context}]\n",
    "    )\n",
    "    \n",
    "    # Print the response and add it to the messages list\n",
    "    chat_message = response.choices[0].message.content\n",
    "    print(f\"Bot: {chat_message}\"+'\\n')\n",
    "    messages.append({\"role\": \"assistant\", \"content\": chat_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gigibs/Documents/envs/data_feminism/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b173dc1039264d75b2723adee1cdd5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bc83f1b7194eb1bde7b7e9d15ca845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cfd3f0f2444bb683cd33536637bb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641f55763dc34908818c91c490853fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6efa0755c114667972f459d68dfb8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f1a494e76c4d1fa1692936a85598c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d342c87515b04663a10517d59cd8d06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4375fdf93a8d42848dda3a017ac5817f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0604870b4d454075bf9ced8e5d4ebb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a49b00fce04d18ad3db5e6ca642d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ceb98a75fed420dbf29dd54f7f2270b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name='all-MiniLM-L6-v2')\n",
    "metadata_options = {\"hnsw:space\": \"cosine\" }\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(name=\"data-feminism\", metadata=metadata_options, embedding_function=sentence_transformer_ef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all chapters to embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = glob.glob(\"docs/*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['docs/Ch2.pdf',\n",
       " 'docs/Ch4.pdf',\n",
       " 'docs/Intro.pdf',\n",
       " 'docs/Ch7.pdf',\n",
       " 'docs/Conclusion.pdf',\n",
       " 'docs/Ch1.pdf',\n",
       " 'docs/Ch3.pdf',\n",
       " 'docs/Ch5.pdf',\n",
       " 'docs/Ch6.pdf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert just one chapter to embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing chapter docs/Ch2.pdf\n",
      "processing chapter docs/Ch4.pdf\n",
      "processing chapter docs/Intro.pdf\n",
      "processing chapter docs/Ch7.pdf\n",
      "processing chapter docs/Conclusion.pdf\n",
      "processing chapter docs/Ch1.pdf\n",
      "processing chapter docs/Ch3.pdf\n",
      "processing chapter docs/Ch5.pdf\n",
      "processing chapter docs/Ch6.pdf\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(f\"processing chapter {doc}\")\n",
    "    loader = PyPDFLoader(doc)\n",
    "    data = loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        uuid_name = uuid.uuid1()\n",
    "        collection.add(ids=[str(uuid_name)], documents=chunk.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query_text):\n",
    "    results = collection.query(query_texts=[query_text],n_results=6)\n",
    "    return results['documents']\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "  # Create a list to store all the messages for context\n",
    "  messages = []\n",
    "  messages.append({\n",
    "      \"role\": \"system\", \n",
    "      \"content\": \"You are a helpful assistant who's been given Data Feminism Chapter as context. \\\n",
    "      When the user asks a question, use the data feminism context to answer the question. \\\n",
    "      If the message is a greeting, just respond normally.\" \n",
    "  })  \n",
    "  \n",
    "  while True:\n",
    "    # list to store all the retrievals from Chroma\n",
    "    context = []\n",
    "    \n",
    "    # Prompt user for input\n",
    "    message = input(\"User: \")\n",
    "    print(f\"User: {message}\"+'\\n')\n",
    "    \n",
    "    # Exit program if user inputs \"quit\"\n",
    "    if message.lower() == \"quit\":\n",
    "      break\n",
    "    \n",
    "    #retrieve necessary context\n",
    "    context = retrieve_context(message)\n",
    "    # context_string = ', '.join([str(elem) for elem in context])\n",
    "    \n",
    "    message_with_context = f''' \n",
    "    \n",
    "    You are a helpful bot who answers concisely. Use this context: \n",
    "    {context} \n",
    "    \n",
    "    To answer the question: {message}. \n",
    "    \n",
    "    If you don't know the answer from the context, say you don't know.\n",
    "    '''\n",
    "    \n",
    "    # Add each new message to the list\n",
    "    messages.append({\"role\": \"user\", \"content\": message_with_context})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"llama3\",\n",
    "      messages=[{\"role\": \"user\", \"content\": message_with_context}]\n",
    "    )\n",
    "    \n",
    "    # Print the response and add it to the messages list\n",
    "    chat_message = response.choices[0].message.content\n",
    "    print(f\"Bot: {chat_message}\"+'\\n')\n",
    "    messages.append({\"role\": \"assistant\", \"content\": chat_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: test\n",
      "\n",
      "Bot: I don't know.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  hi, what are your thoughts on police violence?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hi, what are your thoughts on police violence?\n",
      "\n",
      "Bot: I can provide a concise answer based on the provided context.\n",
      "\n",
      "According to the text, Cathy O'Neil in her book \"Weapons of Math Destruction\" describes a \"pernicious feedback loop\" where biased data is amplified by computational systems, perpetuating racial bias and criminalization of poverty. She suggests opening up these systems to mitigate their effects.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  is police more violent towards black people?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: is police more violent towards black people?\n",
      "\n",
      "Bot: According to the text, yes, police violence has been shown to be a problem for Black women. The campaign #SayHerName aims to make visible the gendered dimensions of police violence against Black women.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  can you help me build arguments to say that the police is more violent towards this demographic?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: can you help me build arguments to say that the police is more violent towards this demographic?\n",
      "\n",
      "Bot: Based on the provided context, here are some potential arguments for why the police may be more violent towards a particular demographic:\n",
      "\n",
      "1. The data collected in PredPol's algorithm is biased because it reflects historical crime data and US policing practices that have disproportionately surveilled and patrolled neighborhoods of color. This can lead to predictive models that favor surveillance and violence against these communities.\n",
      "2. The questionnaire used to determine a person's risk score asks questions that serve as proxies for race, such as whether someone was raised by a single mother or has been arrested in the past. These questions are linked to structural inequalities embedded in US culture, which disproportionately affect certain racial groups.\n",
      "3. Studies have shown that Black kids are punished more harshly than white kids for the same minor infractions, starting as early as preschool. This suggests that there may be a pattern of excessive force or violence used by police against Black children and adults.\n",
      "\n",
      "Some potential arguments based on these points:\n",
      "\n",
      "* The PredPol algorithm's reliance on biased data and historical crime patterns perpetuates systemic racism, leading to increased surveillance and violence towards communities of color.\n",
      "* The questionnaire used to determine risk scores is flawed because it uses proxies for race that are linked to structural inequalities, which can lead to biased decisions about who should be targeted by police.\n",
      "* The disproportionate punishment of Black children highlights a pattern of excessive force or violence used against Black individuals by police, which reinforces systemic racism.\n",
      "\n",
      "Please note that these arguments are based on the provided context and may not reflect the entire range of factors contributing to police violence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
